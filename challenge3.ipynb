{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from moviepy.editor import *\n",
    "from PIL import Image\n",
    "import os\n",
    "import time\n",
    "from annoy import AnnoyIndex\n",
    "import random\n",
    "from scipy.cluster.vq import vq, kmeans, whiten\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from nltk.cluster.kmeans import KMeansClusterer\n",
    "import nltk\n",
    "\n",
    "\n",
    "\n",
    "def video_to_hash(path, dimensionality = 3, image_size = 8):\n",
    "\n",
    "    #clip = VideoFileClip(\"videos/0HH3N4OZUXUB.mp4\")\n",
    "    clip = VideoFileClip(path)\n",
    "\n",
    "    hashes = np.array([])\n",
    "    for t in np.linspace(0, clip.duration, dimensionality):\n",
    "        im = Image.fromarray(clip.get_frame(t), \"RGB\")\n",
    "        im = im.resize((image_size, image_size), Image.ANTIALIAS)\n",
    "        red, green, blue = im.split()\n",
    "\n",
    "        pixels_r = list(red.getdata())\n",
    "        pixels_g = list(green.getdata())\n",
    "        pixels_b = list(blue.getdata())\n",
    "\n",
    "        avg_r = sum(pixels_r)/len(pixels_r)\n",
    "        avg_g = sum(pixels_g)/len(pixels_g)\n",
    "        avg_b = sum(pixels_b)/len(pixels_b)\n",
    "\n",
    "        bits_r = \"\".join(map(lambda pixel_r: '1' if pixel_r < avg_r else '0', pixels_r))\n",
    "        bits_g = \"\".join(map(lambda pixel_g: '1' if pixel_g < avg_g else '0', pixels_g))\n",
    "        bits_b = \"\".join(map(lambda pixel_b: '1' if pixel_b < avg_b else '0', pixels_b))\n",
    "\n",
    "        hashes = np.append(hashes, np.array(int(bits_r, 2)))\n",
    "        hashes = np.append(hashes, np.array(int(bits_g, 2)))\n",
    "        hashes = np.append(hashes, np.array(int(bits_b, 2)))\n",
    "        \n",
    "    return np.array([hashes]).astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.187987565994263\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# SETTINGS\n",
    "dimensionality = 5 # dimensionality of points PER COLOUR CHANNEL (x3)\n",
    "image_size = 8 # size of image in pixels - e.g. 8^2 = 64 bit hash\n",
    "directory = \"videos/\"\n",
    "num_all_points = len(os.listdir(directory))\n",
    "num_points = 10\n",
    "dict_file_names = {}\n",
    "\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "points = np.zeros(shape=(num_points,3*dimensionality)).astype(int)\n",
    "i = 0\n",
    "for file in os.listdir(directory):\n",
    "    if i > num_points-1: break\n",
    "    \n",
    "    filename = os.fsdecode(file)\n",
    "    \n",
    "    newpoint = video_to_hash(os.path.join(directory, filename), dimensionality, image_size).astype(int)\n",
    "    points[i,:] = newpoint.astype(int)\n",
    "    dict_file_names[tuple(newpoint.flatten())] = filename\n",
    "    \n",
    "    i += 1;\n",
    "\n",
    "\n",
    "\n",
    "pickle_out = open(\"dict.pickle\",\"wb\")\n",
    "pickle.dump(dict_file_names, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "\n",
    "np.savetxt(\"points\", points)\n",
    "t2 = time.time()\n",
    "print(t2-t1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-9223372036854775808\n",
      "-9.22337203685e+18\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'float' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-82-c978cc923839>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mkclusterer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKMeansClusterer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdistance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhamming_distance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrepeats\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mavoid_empty_clusters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0massigned_clusters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkclusterer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0massign_clusters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/redzin/anaconda3/lib/python3.5/site-packages/nltk/cluster/util.py\u001b[0m in \u001b[0;36mcluster\u001b[1;34m(self, vectors, assign_clusters, trace)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[1;31m# call abstract method to cluster the vectors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster_vectorspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[1;31m# assign the vectors to clusters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/redzin/anaconda3/lib/python3.5/site-packages/nltk/cluster/kmeans.py\u001b[0m in \u001b[0;36mcluster_vectorspace\u001b[1;34m(self, vectors, trace)\u001b[0m\n\u001b[0;32m     98\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmeanss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m                         \u001b[0md\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sum_distances\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmeanss\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeanss\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mmin_difference\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0md\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mmin_difference\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m                     \u001b[0mmin_difference\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_means\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeanss\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/redzin/anaconda3/lib/python3.5/site-packages/nltk/cluster/kmeans.py\u001b[0m in \u001b[0;36m_sum_distances\u001b[1;34m(self, vectors1, vectors2)\u001b[0m\n\u001b[0;32m    158\u001b[0m         \u001b[0mdifference\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvectors1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvectors2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m             \u001b[0mdifference\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_distance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdifference\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-82-c978cc923839>\u001b[0m in \u001b[0;36mhamming_distance\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m^\u001b[0m\u001b[0mbin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m^\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"1\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'float' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "data = np.loadtxt(\"points\")\n",
    "pickle_in = open(\"dict.pickle\",\"rb\")\n",
    "names = pickle.load(pickle_in)\n",
    "\n",
    "\n",
    "from scipy.cluster.vq import vq, kmeans, whiten\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "k = 10\n",
    "\n",
    "# Whiten data\n",
    "whitened = whiten(data)\n",
    "# Find 2 clusters in the data\n",
    "codebook, distortion = kmeans(whitened, k)\n",
    "\n",
    "\n",
    "def hamming_distance(x, y):\n",
    "    print(x[0].astype(int))\n",
    "    print(y[0])\n",
    "    print((bin(x[0].item())^bin(y[0].item())).count(\"1\"))\n",
    "    return sum([bin(x[i]^y[i]).count(\"1\") for i in np.size(x)])\n",
    "\n",
    "kclusterer = KMeansClusterer(k, distance=hamming_distance, repeats=25, avoid_empty_clusters = True)\n",
    "assigned_clusters = kclusterer.cluster(data, assign_clusters=True)\n",
    "\n",
    "\n",
    "#clusters = [[] for x in range(k)]\n",
    "#for i in range(k):\n",
    "#    clusters[i] = []\n",
    "\n",
    "\n",
    "#for i in range(np.size(data, 0)):\n",
    "#    d = []\n",
    "#    for j in range(k):\n",
    "#        d.append(np.linalg.norm(codebook[j] - data[i,:]))\n",
    "    #print(np.argmin(d), np.min(d))\n",
    "#    print(d)\n",
    "    #clusters[np.argmin(d)].append(names[tuple(data[i,:].flatten())][:-4])\n",
    "\n",
    "#clusters\n",
    "\n",
    "print(assigned_clusters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot whitened data and cluster centers in red\n",
    "#plt.scatter(whitened[:, 0], whitened[:, 1])\n",
    "#plt.scatter(codebook[:, 0], codebook[:, 1], c='r')\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "data = np.loadtxt(\"points\")\n",
    "\n",
    "t = AnnoyIndex(dimensionality*3, metric = \"euclidean\")  # Length of item vector that will be indexed\n",
    "\n",
    "for i in range(10):#np.size(data, 0)):\n",
    "    #print(data[i,:].flatten())\n",
    "    t.add_item(i, data[i,:].flatten())\n",
    "\n",
    "t.build(10) # 10 trees\n",
    "t.save('test.ann')\n",
    "#print(t.get_nns_by_item(0, num_all_points))\n",
    "#print(t.get_n_items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
