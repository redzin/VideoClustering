{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from moviepy.editor import *\n",
    "from PIL import Image\n",
    "import os\n",
    "import time\n",
    "#from annoy import AnnoyIndex\n",
    "import random\n",
    "from scipy.cluster.vq import vq, kmeans, whiten\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from nltk.cluster.kmeans import KMeansClusterer\n",
    "import nltk\n",
    "\n",
    "\n",
    "\n",
    "def video_to_hash(path, dimensionality = 3, image_size = 7):\n",
    "\n",
    "    #clip = VideoFileClip(\"videos/0HH3N4OZUXUB.mp4\")\n",
    "    clip = VideoFileClip(path)\n",
    "\n",
    "    hashes = np.array([])\n",
    "    for t in np.linspace(0, clip.duration, dimensionality):\n",
    "        im = Image.fromarray(clip.get_frame(t), \"RGB\")\n",
    "        im = im.resize((image_size, image_size), Image.ANTIALIAS)\n",
    "        red, green, blue = im.split()\n",
    "\n",
    "        pixels_r = list(red.getdata())\n",
    "        pixels_g = list(green.getdata())\n",
    "        pixels_b = list(blue.getdata())\n",
    "\n",
    "        avg_r = sum(pixels_r)/len(pixels_r)\n",
    "        avg_g = sum(pixels_g)/len(pixels_g)\n",
    "        avg_b = sum(pixels_b)/len(pixels_b)\n",
    "\n",
    "        bits_r = \"\".join(map(lambda pixel_r: '1' if pixel_r < avg_r else '0', pixels_r))\n",
    "        bits_g = \"\".join(map(lambda pixel_g: '1' if pixel_g < avg_g else '0', pixels_g))\n",
    "        bits_b = \"\".join(map(lambda pixel_b: '1' if pixel_b < avg_b else '0', pixels_b))\n",
    "\n",
    "        hashes = np.append(hashes, np.array([int(x) for x in bits_r]))\n",
    "        hashes = np.append(hashes, np.array([int(x) for x in bits_g]))\n",
    "        hashes = np.append(hashes, np.array([int(x) for x in bits_b]))\n",
    "        \n",
    "    return np.array([hashes])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# SETTINGS\n",
    "dimensionality = 5 # dimensionality of points PER COLOUR CHANNEL (x3)\n",
    "image_size = 8 # size of image in pixels - e.g. 8^2 = 64 bit hash\n",
    "directory = \"../videos/\"\n",
    "num_all_points = len(os.listdir(directory))\n",
    "num_points = 20\n",
    "dict_file_names = {}\n",
    "\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "points = np.zeros(shape=(num_points,3*image_size**2*dimensionality)).astype(int)\n",
    "i = 0\n",
    "for file in os.listdir(directory):\n",
    "    if i > num_points-1: break\n",
    "    \n",
    "    filename = os.fsdecode(file)\n",
    "    \n",
    "    newpoint = video_to_hash(os.path.join(directory, filename), dimensionality, image_size).astype(int)\n",
    "    points[i,:] = newpoint.astype(int)\n",
    "    dict_file_names[tuple(newpoint.flatten())] = filename[:-4]\n",
    "\n",
    "    i += 1;\n",
    "\n",
    "\n",
    "\n",
    "pickle_out = open(\"dict.pickle\",\"wb\")\n",
    "pickle.dump(dict_file_names, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "np.savetxt(\"points\", points)\n",
    "t2 = time.time()\n",
    "print(\"Execution Time: \" + str(t2-t1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = np.loadtxt(\"points\")\n",
    "pickle_in = open(\"dict.pickle\",\"rb\")\n",
    "names = pickle.load(pickle_in)\n",
    "\n",
    "k = 5\n",
    "\n",
    "# Whiten data\n",
    "whitened = whiten(data)\n",
    "# Find 2 clusters in the data\n",
    "codebook, distortion = kmeans(whitened, k)\n",
    "\n",
    "\n",
    "clusters = [[] for x in range(k)]\n",
    "for i in range(k):\n",
    "    clusters[i] = []\n",
    "\n",
    "\n",
    "for i in range(np.size(data, 0)):\n",
    "    d = []\n",
    "    for j in range(k):\n",
    "        d.append(np.linalg.norm(codebook[j] - data[i,:]))\n",
    "    print(np.argmin(d), np.min(d))\n",
    "    print(d)\n",
    "    clusters[np.argmin(d)].append(names[tuple(data[i,:].flatten())][:-4])\n",
    "\n",
    "clusters\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def hamming_distance(x, y):\n",
    "    x = x.astype(int)\n",
    "    y = y.astype(int)\n",
    "    return sum([(bin(x[i] ^ y[i])).count('1') for i in range(dimensionality*3)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = np.loadtxt(\"points\")\n",
    "\n",
    "t = AnnoyIndex(dimensionality*3, metric = \"euclidean\")  # Length of item vector that will be indexed\n",
    "\n",
    "for i in range(10):#np.size(data, 0)):\n",
    "    #print(data[i,:].flatten())\n",
    "    t.add_item(i, data[i,:].flatten())\n",
    "\n",
    "t.build(10) # 10 trees\n",
    "t.save('test.ann')\n",
    "#print(t.get_nns_by_item(0, num_all_points))\n",
    "#print(t.get_n_items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
